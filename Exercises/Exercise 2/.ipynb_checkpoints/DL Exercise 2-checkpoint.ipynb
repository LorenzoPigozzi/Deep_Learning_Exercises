{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rotary-quality",
   "metadata": {},
   "source": [
    "# Deep Learning Exercise 2\n",
    "\n",
    "## Second week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "straight-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "marine-angel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# importing the dataset 'boston_housing' from the Keras package\n",
    "from keras.datasets import boston_housing\n",
    "# defining the train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-pickup",
   "metadata": {},
   "source": [
    "## First Part\n",
    "### Deep-NN from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-mileage",
   "metadata": {},
   "source": [
    "### Step 1 :\n",
    "### Exploration and pre-processing of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "minute-pledge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02177</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>7.610</td>\n",
       "      <td>15.7</td>\n",
       "      <td>6.2700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>395.38</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.89822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6310</td>\n",
       "      <td>4.970</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.3325</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>375.52</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>6.037</td>\n",
       "      <td>34.5</td>\n",
       "      <td>5.9853</td>\n",
       "      <td>5.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.69311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>6.376</td>\n",
       "      <td>88.4</td>\n",
       "      <td>2.5671</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>391.43</td>\n",
       "      <td>14.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.21977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4480</td>\n",
       "      <td>5.602</td>\n",
       "      <td>62.0</td>\n",
       "      <td>6.0877</td>\n",
       "      <td>3.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>396.90</td>\n",
       "      <td>16.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.16211</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>6.240</td>\n",
       "      <td>16.3</td>\n",
       "      <td>4.4290</td>\n",
       "      <td>3.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>6.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.03466</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>6.031</td>\n",
       "      <td>23.3</td>\n",
       "      <td>6.6407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>362.25</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>2.14918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.709</td>\n",
       "      <td>98.5</td>\n",
       "      <td>1.6232</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>261.95</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.01439</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4010</td>\n",
       "      <td>6.604</td>\n",
       "      <td>18.8</td>\n",
       "      <td>6.2196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>376.70</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2    3       4      5      6       7     8      9   \\\n",
       "0    1.23247   0.0   8.14  0.0  0.5380  6.142   91.7  3.9769   4.0  307.0   \n",
       "1    0.02177  82.5   2.03  0.0  0.4150  7.610   15.7  6.2700   2.0  348.0   \n",
       "2    4.89822   0.0  18.10  0.0  0.6310  4.970  100.0  1.3325  24.0  666.0   \n",
       "3    0.03961   0.0   5.19  0.0  0.5150  6.037   34.5  5.9853   5.0  224.0   \n",
       "4    3.69311   0.0  18.10  0.0  0.7130  6.376   88.4  2.5671  24.0  666.0   \n",
       "..       ...   ...    ...  ...     ...    ...    ...     ...   ...    ...   \n",
       "399  0.21977   0.0   6.91  0.0  0.4480  5.602   62.0  6.0877   3.0  233.0   \n",
       "400  0.16211  20.0   6.96  0.0  0.4640  6.240   16.3  4.4290   3.0  223.0   \n",
       "401  0.03466  35.0   6.06  0.0  0.4379  6.031   23.3  6.6407   1.0  304.0   \n",
       "402  2.14918   0.0  19.58  0.0  0.8710  5.709   98.5  1.6232   5.0  403.0   \n",
       "403  0.01439  60.0   2.93  0.0  0.4010  6.604   18.8  6.2196   1.0  265.0   \n",
       "\n",
       "       10      11     12  \n",
       "0    21.0  396.90  18.72  \n",
       "1    14.7  395.38   3.11  \n",
       "2    20.2  375.52   3.26  \n",
       "3    20.2  396.90   8.01  \n",
       "4    20.2  391.43  14.65  \n",
       "..    ...     ...    ...  \n",
       "399  17.9  396.90  16.20  \n",
       "400  18.6  396.90   6.59  \n",
       "401  16.9  362.25   7.83  \n",
       "402  14.7  261.95  15.79  \n",
       "403  15.6  376.70   4.38  \n",
       "\n",
       "[404 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the input train matrix\n",
    "pd.DataFrame(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "removed-chile",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      15.2\n",
       "1      42.3\n",
       "2      50.0\n",
       "3      21.1\n",
       "4      17.7\n",
       "       ... \n",
       "399    19.4\n",
       "400    25.2\n",
       "401    19.4\n",
       "402    19.4\n",
       "403    29.1\n",
       "Length: 404, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the target vector\n",
    "pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "healthy-buddy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "subjective-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization of the variables\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-republican",
   "metadata": {},
   "source": [
    "### Step 2 :\n",
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "departmental-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "union-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#creating the first hidden layer\n",
    "model.add(Dense(units = 64, activation='relu', input_dim =13))\n",
    "#creating the second hidden layer \n",
    "model.add(Dense(units = 64, activation='relu'))\n",
    "# creating the output layer\n",
    "model.add(Dense(units = 1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-cabin",
   "metadata": {},
   "source": [
    "### Step 3 :\n",
    "### Training and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "internal-knight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 557.9760 - mae: 21.7316\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 505.1908 - mae: 20.4568\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 433.6317 - mae: 18.6379\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 335.8727 - mae: 15.9712\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 224.4279 - mae: 12.4419\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 128.4397 - mae: 8.7193\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 79.5234 - mae: 6.8015\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 57.8542 - mae: 5.7520\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 42.7233 - mae: 4.8553\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 33.6319 - mae: 4.2754\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 28.6295 - mae: 3.9116\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 25.7921 - mae: 3.7134\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 23.7617 - mae: 3.5822\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 22.4648 - mae: 3.4962\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 21.2411 - mae: 3.4006\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 20.2174 - mae: 3.3020\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 19.2569 - mae: 3.2178\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18.5952 - mae: 3.1771\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 17.8263 - mae: 3.0900\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 17.0102 - mae: 3.0050\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 16.4430 - mae: 2.9517\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 16.0014 - mae: 2.9076\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 15.3830 - mae: 2.8290\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 9.7439 - mae: 2.403 - 0s 2ms/step - loss: 14.8832 - mae: 2.7861\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 14.4441 - mae: 2.7457\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 13.9569 - mae: 2.6982\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 13.6527 - mae: 2.6744\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 13.2562 - mae: 2.6247\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 12.8948 - mae: 2.5840\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 12.6061 - mae: 2.5537\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 12.2843 - mae: 2.5210\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 11.9949 - mae: 2.4918\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 11.7791 - mae: 2.4698\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 11.5862 - mae: 2.4284\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 11.6068 - mae: 2.4693\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 11.0127 - mae: 2.3970\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 10.9283 - mae: 2.3756\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 10.7400 - mae: 2.3637\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 10.5338 - mae: 2.3521\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 10.3462 - mae: 2.3229\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 10.1933 - mae: 2.3054\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 10.0630 - mae: 2.2968\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.9112 - mae: 2.2866\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 988us/step - loss: 9.8253 - mae: 2.2618\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.5846 - mae: 2.2482\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.5102 - mae: 2.2470\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.4020 - mae: 2.2248\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 964us/step - loss: 9.2721 - mae: 2.2150\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 808us/step - loss: 9.1686 - mae: 2.2012\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 9.0679 - mae: 2.1857\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.9693 - mae: 2.1757\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 862us/step - loss: 8.9239 - mae: 2.1700\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 951us/step - loss: 8.8872 - mae: 2.1616\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.7766 - mae: 2.1448\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.6943 - mae: 2.1594\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 756us/step - loss: 8.5738 - mae: 2.1270\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.4913 - mae: 2.1042\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 8.4748 - mae: 2.1128\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 939us/step - loss: 8.3966 - mae: 2.0948\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 935us/step - loss: 8.2986 - mae: 2.0941\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 869us/step - loss: 8.2349 - mae: 2.0914\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 690us/step - loss: 8.1351 - mae: 2.0653\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 721us/step - loss: 8.1549 - mae: 2.0520\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 980us/step - loss: 8.0463 - mae: 2.0590\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 424us/step - loss: 8.0736 - mae: 2.0593\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.9678 - mae: 2.0294\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 939us/step - loss: 7.9055 - mae: 2.0221\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 955us/step - loss: 7.8200 - mae: 2.0367\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 897us/step - loss: 7.8663 - mae: 2.0162\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 7.8123 - mae: 2.0244\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 890us/step - loss: 7.6129 - mae: 1.9910\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 504us/step - loss: 7.6131 - mae: 1.9829\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 935us/step - loss: 7.6529 - mae: 2.0053\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 734us/step - loss: 7.5031 - mae: 1.9543\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 857us/step - loss: 7.5550 - mae: 1.9587\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 804us/step - loss: 7.4835 - mae: 1.9867\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 911us/step - loss: 7.4262 - mae: 1.9551\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 839us/step - loss: 7.3288 - mae: 1.9322\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 893us/step - loss: 7.3063 - mae: 1.9530\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 901us/step - loss: 7.3130 - mae: 1.9218\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 886us/step - loss: 7.2680 - mae: 1.9348\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 965us/step - loss: 7.1758 - mae: 1.9091\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 968us/step - loss: 7.1037 - mae: 1.9080\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 862us/step - loss: 7.2439 - mae: 1.9075\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 896us/step - loss: 7.1113 - mae: 1.9266\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 771us/step - loss: 7.0876 - mae: 1.9037\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.9162 - mae: 1.8852\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 871us/step - loss: 6.8883 - mae: 1.8829\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 939us/step - loss: 6.8510 - mae: 1.8595\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 6.8025 - mae: 1.8634\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 890us/step - loss: 6.7311 - mae: 1.8590\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 938us/step - loss: 6.7522 - mae: 1.8446\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 972us/step - loss: 6.7848 - mae: 1.8574\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 965us/step - loss: 6.6501 - mae: 1.8591\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 926us/step - loss: 6.7269 - mae: 1.8516\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 941us/step - loss: 6.6815 - mae: 1.8242\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 982us/step - loss: 6.5413 - mae: 1.8156\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 842us/step - loss: 6.5177 - mae: 1.8361\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 6.4207 - mae: 1.8075\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 6.3901 - mae: 1.8169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f5b9e66e50>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the optimizer, the loss function and the metric to use\n",
    "model.compile(optimizer ='adam', loss='mse', metrics='mae')\n",
    "\n",
    "# fitting the training set\n",
    "model.fit(x_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "substantial-helmet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.056750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.462858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.086176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.294033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.227493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>50.594650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>27.575466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>49.016727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>31.598215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>21.217831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     8.056750\n",
       "1    18.462858\n",
       "2    21.086176\n",
       "3    33.294033\n",
       "4    25.227493\n",
       "..         ...\n",
       "97   50.594650\n",
       "98   27.575466\n",
       "99   49.016727\n",
       "100  31.598215\n",
       "101  21.217831\n",
       "\n",
       "[102 rows x 1 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# displaying the predictions\n",
    "pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "coastal-wallpaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.082073973341863"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the mse of the prediction\n",
    "mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-syndicate",
   "metadata": {},
   "source": [
    "## Second Part\n",
    "### Regularizations and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "genetic-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "lesser-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding to the previous model both L1 and L2 regularizations\n",
    "\n",
    "model_2 = Sequential()\n",
    "\n",
    "#creating the first hidden layer\n",
    "model_2.add(Dense(units = 64, \n",
    "                  activation='relu', \n",
    "                  kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01),\n",
    "                  input_dim =13))\n",
    "\n",
    "#creating the second hidden layer \n",
    "model_2.add(Dense(units = 64,\n",
    "                  kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01),\n",
    "                  activation='relu'))\n",
    "\n",
    "# creating the output layer\n",
    "model_2.add(Dense(units = 1, \n",
    "                  activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "specified-promise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f5bb312e80>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the optimizer, the loss function and the metric to use\n",
    "model_2.compile(optimizer ='adam', loss='mse', metrics='mae')\n",
    "\n",
    "# fitting the training set\n",
    "model_2.fit(x_train, y_train, epochs = 100, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "billion-irish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.347278873479876"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting the test set\n",
    "y_pred_2 = model_2.predict(x_test)\n",
    "\n",
    "# Computing the mse of the prediction\n",
    "mean_squared_error(y_pred_2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "alternate-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding to the previous model a dropout layer\n",
    "\n",
    "model_3 = Sequential()\n",
    "\n",
    "#creating the first hidden layer\n",
    "model_3.add(Dense(units = 64, \n",
    "                  activation='relu', \n",
    "                  kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01),\n",
    "                  input_dim =13))\n",
    "# dropout layer\n",
    "model_3.add(layers.Dropout(.2))\n",
    "\n",
    "#creating the second hidden layer \n",
    "model_3.add(Dense(units = 64,\n",
    "                  kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01),\n",
    "                  activation='relu'))\n",
    "\n",
    "# dropout layer\n",
    "model_3.add(layers.Dropout(.2))\n",
    "\n",
    "# creating the output layer\n",
    "model_3.add(Dense(units = 1, \n",
    "                  activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "general-masters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f5be6d5d00>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the optimizer, the loss function and the metric to use\n",
    "model_3.compile(optimizer ='adam', loss='mse', metrics='mae')\n",
    "\n",
    "# fitting the training set\n",
    "model_3.fit(x_train, y_train, epochs = 100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cooperative-danger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.965975131660514"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting the test set\n",
    "y_pred_3 = model_3.predict(x_test)\n",
    "\n",
    "# Computing the mse of the prediction\n",
    "mean_squared_error(y_pred_3, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-springfield",
   "metadata": {},
   "source": [
    "## Third Part\n",
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "greek-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "white-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function that build the model\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    #creating the first hidden layer\n",
    "    model.add(Dense(units = 64, \n",
    "                      activation='relu', \n",
    "                      kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01),\n",
    "                      input_dim =13))\n",
    "    # dropout layer\n",
    "    model.add(layers.Dropout(.2))\n",
    "\n",
    "    #creating the second hidden layer \n",
    "    model.add(Dense(units = 64,\n",
    "                      kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01),\n",
    "                      activation='relu'))\n",
    "\n",
    "    # dropout layer\n",
    "    model.add(layers.Dropout(.2))\n",
    "\n",
    "    # creating the output layer\n",
    "    model.add(Dense(units = 1, \n",
    "                      activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "creative-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the KerasClassifier\n",
    "model = KerasClassifier(build_fn=build_model, batch_size = 10, epochs = 100)\n",
    "# storing the results inside a variable 'accuracies'\n",
    "accuracies = cross_val_score(estimator = model, X = x_train, y = y_train, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "choice-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the cross validation results\n",
    "mean_accuracy_cv = accuracies.mean()\n",
    "mean_accuracy_cv = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-singapore",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-adapter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
